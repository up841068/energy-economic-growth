import pandas as pd

from google.cloud import bigquery
from colorama import Fore, Style
from pathlib import Path

from energy_economy.params import *

#OK!
def get_data_with_cache(
        gcp_project:str,
        query:str,
        cache_path:Path,
        data_has_header=True
        ) -> pd.DataFrame:
    """
    Retrieve `query` data from BigQuery, or from `cache_path` if the file exists #OK!
    Store query result as a local CSV if it doesn't exist locally for future use #OK!
    """

    # Checks if local file where CSV would be stored exists, and if so, get processed data from there
    if cache_path.is_file():
        print(Fore.BLUE + "\nLoad data from local CSV..." + Style.RESET_ALL)
        df = pd.read_csv(cache_path, header='infer' if data_has_header else None)

    # If local file doesn't exist, get processed data from BigQuery and saves in local file
    else:
        print(Fore.BLUE + "\nLoad data from BigQuery server..." + Style.RESET_ALL)
        client = bigquery.Client(project=gcp_project)
        query_job = client.query(query)
        result = query_job.result()
        df = result.to_dataframe()

        # Store as CSV if the BQ query returned at least one valid line
        if df.shape[0] > 1:
            df.to_csv(cache_path, header=data_has_header, index=False)

    print(f"âœ… Data loaded, with shape {df.shape}")

    return df
